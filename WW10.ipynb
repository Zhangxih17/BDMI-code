{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_to_get_faster(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x+b\n",
    "    return x\n",
    "\n",
    "a_function_that_uses_a_graph = tf.function(function_to_get_faster)\n",
    "\n",
    "x1 = tf.constant([[1.0,2.0]])\n",
    "y1 = tf.constant([[2.0],[3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "a_function_that_uses_a_graph(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First branch, with graph: 1.0\n",
      "Second branch, with graph: [4. 4.]\n"
     ]
    }
   ],
   "source": [
    "def my_function(x):\n",
    "    if tf.reduce_sum(x) <= 1:\n",
    "        return x*x\n",
    "    else:\n",
    "        return x-1\n",
    "\n",
    "a_function = tf.function(my_function)\n",
    "\n",
    "print(\"First branch, with graph:\", a_function(tf.constant(1.0)).numpy())\n",
    "print(\"Second branch, with graph:\", a_function(tf.constant([5.0, 5.0])).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "\n",
    "def inner_function(x, y, b):\n",
    "  x = tf.matmul(x, y)\n",
    "  x = x + b\n",
    "  return x\n",
    "\n",
    "# Use the decorator\n",
    "@tf.function\n",
    "def outer_function(x):\n",
    "  y = tf.constant([[2.0], [3.0]])\n",
    "  b = tf.constant(4.0)\n",
    "\n",
    "  return inner_function(x, y, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    def __init__(self, in_features, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable(tf.random.normal([in_features, out_features]),name='w')\n",
    "        self.b = tf.Variable(tf.zeros([out_features]),name='b')\n",
    "    def __call__(self,x):\n",
    "        y = tf.matmul(self.w, x)+self.b\n",
    "        return tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.7431395 , 0.7431395 , 0.7431395 ],\n",
       "       [0.30271006, 0.30271006, 0.30271006],\n",
       "       [0.56767285, 0.56767285, 0.56767285]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_module=Dense(in_features=3, out_features=3,name='mymodule')\n",
    "my_module(tf.constant([[0.0288],[-0.3256],[0.5925]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 从层到模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "    \n",
    "    self.dense_1 = Dense(in_features=3, out_features=3)\n",
    "    self.dense_2 = Dense(in_features=3, out_features=1)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "# make a model\n",
    "my_model = SequentialModel(name=\"the_model\")\n",
    "\n",
    "# print(\"Model results: \", my_model(tf.constant([0.0288,-0.3256,0.5925])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 模型存储与恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_checkpoint'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkp_path = \"my_checkpoint\"\n",
    "checkpoint = tf.train.Checkpoint(model=my_model)\n",
    "checkpoint.write(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
       " ('model/dense_1/b/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n",
       " ('model/dense_1/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 3]),\n",
       " ('model/dense_2/b/.ATTRIBUTES/VARIABLE_VALUE', [1]),\n",
       " ('model/dense_2/w/.ATTRIBUTES/VARIABLE_VALUE', [3, 1])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11156), started 0:04:45 ago. (Use '!kill 11156' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3a06b68e012e3c8c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3a06b68e012e3c8c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up logging\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = 'logs/func/%s'%stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "new_model = SequentialModel()\n",
    "\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "\n",
    "outer_function(tf.constant([[1.0,2.0]]))\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"my_func_trace\",\n",
    "        step=0,\n",
    "        profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(my_model, 'the_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-6f0a282edb47>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-6f0a282edb47>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    $ ls -l the_saved_model\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$ ls -l the_saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_W = 3.0\n",
    "TRUE_B = 2.0\n",
    "\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "x = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "noise = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "y = x*TRUE_W+TRUE_B+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-54-6f7808bf4b2d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-54-6f7808bf4b2d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    pip install matplotlib\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Plot all the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x, y, c=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: (<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.0>)\n"
     ]
    }
   ],
   "source": [
    "class MyModel(tf.Module):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    # Initialize the weights to `5.0` and the bias to `0.0`\n",
    "    # In practice, these should be randomly initialized\n",
    "    self.w = tf.Variable(5.0)\n",
    "    self.b = tf.Variable(0.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# List the variables tf.modules's built-in variable aggregation.\n",
    "print(\"Variables:\", model.variables)\n",
    "\n",
    "# Verify the model works\n",
    "assert model(3.0).numpy() == 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes a single loss value for an entire batch\n",
    "def loss(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a callable model, inputs, outputs, and a learning rate...\n",
    "def train(model, x, y, learning_rate):\n",
    "\n",
    "  with tf.GradientTape() as t:\n",
    "    # Trainable variables are automatically tracked by GradientTape\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "  # Use GradientTape to calculate the gradients with respect to W and b\n",
    "  dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "\n",
    "  # Subtract the gradient scaled by the learning rate\n",
    "  model.w.assign_sub(learning_rate * dw)\n",
    "  model.b.assign_sub(learning_rate * db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "# Collect the history of W-values and b-values to plot later\n",
    "Ws, bs = [], []\n",
    "epochs = range(10)\n",
    "\n",
    "# Define a training loop\n",
    "def training_loop(model, x, y):\n",
    "\n",
    "  for epoch in epochs:\n",
    "    # Update the model with the single giant batch\n",
    "    train(model, x, y, learning_rate=0.1)\n",
    "\n",
    "    # Track this before I update\n",
    "    Ws.append(model.w.numpy())\n",
    "    bs.append(model.b.numpy())\n",
    "    current_loss = loss(y, model(x))\n",
    "\n",
    "    print(\"Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f\" %\n",
    "          (epoch, Ws[-1], bs[-1], current_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting: W=%1.2f b=%1.2f, loss=%2.5f\" %\n",
    "      (model.w, model.b, loss(y, model(x))))\n",
    "\n",
    "# Do the training\n",
    "training_loop(model, x, y)\n",
    "\n",
    "# Plot it\n",
    "plt.plot(epochs, Ws, \"r\",\n",
    "         epochs, bs, \"b\")\n",
    "\n",
    "plt.plot([TRUE_W] * len(epochs), \"r--\",\n",
    "         [TRUE_B] * len(epochs), \"b--\")\n",
    "\n",
    "plt.legend([\"W\", \"b\", \"True W\", \"True b\"])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
